来源：DeepTech深科技
　　一种新的方法正在让人工智能模型获得人类的 “联想” 能力，甚至能让它识别此前从未见过的事物。
　　来自加拿大滑铁卢大学的博士生伊利亚（Ilia Sucholutsky）和他的博士导师马赛厄斯・尚劳（Matthias Schonlau）教授，首次提出了 “少于一次” 样本学习的概念和方法，并由此为人工智能技术的演进提供了新的思路。
　　相关研究论文于 2020 年 9 月发表在预印本网站 arXiv 上，名为 “‘Less Than One’-Shot Learning： Learning N Classes From M < N Samples”。
　　伊利亚告诉 DeepTech，他们的研究显示，对于机器学习模型来说，理论上通过两个样本（example）即可训练模型学会识别任意数量类别（class）。
　　没人知道，这种方法一旦实现大规模应用，人工智能会迸发出怎样的火花。
　　高企的训练成本
　　机器学习，尤其是深度学习往往需要大量的训练数据。
　　著名的语言模型 GPT-3 使用了 45TB 的数据进行训练，这个过程耗资达到了惊人的 1200 万美元，即使有微软的鼎力相助，训练结束之后发现了一些小 Bug 也不舍得重新训练。
　　目前，GPT-3 是炼丹师们 “大力出奇迹” 的集大成者，但可以预见，不远的将来一定会有新的模型超越并取代它的位置。
　　“更多更大更强” 的思路是没有尽头的。假如我们稍稍停下疲于奔命的脚步，回归到现实中的人类学习过程，就会发现一个触及灵魂的拷问 ——人工智能真的必须依托如此巨量的数据才能够实现吗？
　　相信很多人的答案并不笃定。
　　举个例子，假如现在需要让人工智能模型 “认识” 马这种动物。常规的做法是挑选成百上千的马匹图像对其进行训练。
　　之所以需要如此之多的样本，是因为同样一匹马，仅仅是转换一个拍摄角度，或微调一些肉眼无法观察的像素点，人工智能就会识别失败，所以需要大量的大小、颜色、体态、朝向、品种不一的样本填满人工智能的 “盲区”。
　　即便如此，人工智能的识别成功概率也不能达到 100%，我们离创造真正可以复现大脑理解能力的人工智能还非常遥远。
　　但人类的儿童，却只需要一张看图识字的卡片，便能轻易分辨出唐僧所骑乘的是马，而不是其他外型类似的生物。并且，儿童一旦学会识别某种事物，这项技能终其一生都很难忘记，只会越来越熟练。
　　更有甚者，儿童可以在没有任何真实示例的情况下 “认出” 一个新的物体。例如，展示给他们一匹马和一头犀牛的图片，并告诉他们独角兽结合了两者的特点，他们就可以在第一次看到独角兽时认出这个传说中的生物。
图 | 犀牛 + 马 = 犀牛马？好吧，这张图并不像独角兽，但一定程度上体现了论文作者的意图。
　　伊利亚和导师认为，人工智能模型也应该具备同样的能力。也就是说，人工智能模型应该可以从 M 个样本中学习到 N 个类别，其中 N 可以远远大于 M。这样，理论上模型就可以识别比训练示例更多的图像，而此前的科研人员可能并未充分挖掘训练数据的全部潜力。
　　他们将这一过程称为 “少于一个” 样本学习（LO-Shot Learning）。
　　考虑到居高不下的训练成本和日益庞大到接近极限的训练数据，这种让人工智能学会 “合理联想” 的方法或许会在未来产生颠覆性影响。
　　如何实现 “少于一个” 样本学习？
　　在此前的一篇论文中，现为麻省理工学院博士生的 Tongzhou Wang 和同事介绍了一种 “蒸馏” 方法，可以将大数据集 “提纯” 为小数据集。
　　作为实践，他们将 MNIST（一个包含了 6 万张从 0 到 9 手写数字图片的业内常用测试数据集）提纯压缩成了一个仅由 10 张图像组成的训练数据集。
　　这些图像不是直接从原始数据集中选取的，而是经由一系列的设计和优化后，赋予了这 10 张图像几乎与整个原始数据集相同的信息。
　　因此，仅仅用这个超精简数据集对人工智能模型进行训练，就可以达到与用 MNIST 所有图像进行训练的模型几乎一致的识别精度。
图 | MNIST 数据集样例
图 | “蒸馏” 后的 MNIST 精简数据集。以上 10 张图是从 MNIST 所含 6 万张图像中提纯出的，可以用于训练人工智能模型，并且它们在识别手写数字时拥有 94% 的准确性。
　　伊利亚和导师从中受到启发，并且认为可以在 Tongzhou Wang 的方法上更进一步 —— 既然可以将 6 万张图像压缩到 10 张，那么为什么不能将它们压缩到 5 张或更少呢？一旦实现，就意味着，通过区区几张图象的训练，人工智能模型就能掌握从 0 到 9 这 10 个数字的各种手写数字图片，从而实现前面所说的 N 大于 M。
　　伊利亚很快发现，想要达到这个效果的诀窍就是创建混合有多个数字特征的图像，然后为它们打上 “软标签（让一个数据点同时成为多个类别成员的矢量表示）”，再来用这些样本训练人工智能模型（类似于前文的马 + 犀牛混合体）。
　　“你可以想象一下数字 3，它看起来有点像 8，但一点都不像 7。” 伊利亚说。

　　“软标签的目的在于标注这些共同的特征，进而以这种方式增加信息密度和维度。因此，相比于直接告诉模型这个图像是 3，我们会说，这个图像有 60% 可能是 3，30% 可能是 8，10% 可能是 0。” 使用这种数据训练出的模型，基本可以达到与常规训练方式一样的精度。
　　“少于一个” 样本学习的局限性
　　当伊利亚和导师成功地使用软标签在 MNIST 上实现 “少于一个” 样本学习后，他们开始思考这个方法能否用于更广阔的领域。人工智能模型从小样本中可以识别出的类别数量是否存在上限？
　　答案是否定的。
　　从理论上来看，使用精心设计的软标签，甚至只用两个示例就可以承载任意数量的类别信息。伊利亚说：“通过两个数据点，你就可以分离出一千个，一万个，甚至是一百万个类别。”
　　伊利亚和导师通过纯数学方式的推导，在论文中证明了这一点。他们使用一种最简单的机器学习算法 ——K-近邻算法（kNN）来表述这一概念，该算法使用图形方法来为对象分类。值得注意的是，他们在 kNN 算法的基础上进行了开发，并将最终的算法称为 SLaPkNN（soft-label prototype kNearest Neighbors）。
　　在进一步说明之前，有必要以水果分类任务为例，简单说明 kNN 算法的核心逻辑。
　　假设我们要训练 kNN 模型识别苹果和橙子，你必须先确定每个水果的特征，这里以颜色（X 轴）、重量（Y 轴）为例。这样你就可以将多个苹果和橙子的信息输入 kNN 模型。
　　kNN 算法会将所有数据点绘制在一张二维图表上，并在苹果和橙子分布点的中间地带绘制边界线。
图 | kNN 算法原理。由图可见，坐标轴上分布着红苹果、青苹果和橙子的数据点。当模型需要判定黑色点属于哪种水果时，它会依据蓝色框选区域内的色彩分布，将比例最大的橙色判断为 “邻近”，进而将黑色点归类为橙子。
　　为了将 kNN 算法应用于 “少于一个” 样本学习，伊利亚和导师创建了一系列微型的合成数据集，并精心设计了它们的软标签。
　　然后，他们让 kNN 算法绘制了它从样本中看到的边界线，发现它成功地将样本分成了比数据点更多的类别。
图 | 上图中，有两个实例可以调节机器学习模型（用黑点表示）。经典的 kNN 算法会在两个点和类别之间分界。但 SLaPkNN 算法在两个类别之间创建了一个新的类别（绿色区域），它代表着一个新标签。这样，研究者用 N-1 个样本实现了 N 类别。
　　通过对类别边界线的复杂编码和样本软标签的调整，他们让 kNN 算法精确画出不同形状的花朵图案。
图 | 作者在论文中炫技。图表上的每个彩色区域代表一个不同的类别，每个图表侧面的饼图则显示了每个数据点的软标签分布。
　　当然，凡事总有两面，这个方法也有其局限性。
　　当伊利亚和导师尝试将 “少于一次” 样本学习的方法应用到其他更复杂的算法（如深度学习等）时，他们发现设计软标签的工作变得异常困难。
　　kNN 算法具有很好的可解释性和可视性，为人们设计标签提供了良好基础。但神经网络是复杂且不可穿透的，这意味着同样的方法未必可行。并且，设计用于 “凝练” 神经网络训练数据的软标签时也有一个主要难点：设计者需要面对庞大的数据集并凝练出有效的内容。
　　这一工作目前看来不可能全部通过人工完成。伊利亚说，他现在正在研究其他方法来设计这些凝练后的合成数据集 —— 无论是手动设计还是使用其他算法进行设计。
　　尽管存在诸多挑战，但不可否认这篇论文为 “少于一次” 样本学习提供了理论基础。“无疑经过凝练的数据集将带来极大的效率提升。” 伊利亚说。
图 | 伊利亚（Ilia Sucholutsky）
　　需要从图像或视频帧中识别成千上万个类别的计算机视觉系统（如自动驾驶）、执行情感分析的自然语言处理系统等都将从中受益。
　　Tongzhou Wang 对此补充道，这篇论文同时也提出了一个非常新颖且重要的目标 ——如何从小数据集中训练强大的模型。
　　从人类的学习经验来看，这是能够实现的，应用领域也异常宽广。从抓捕只有一张照片的犯罪嫌疑人，到识别海上航行的敌方舰艇，都是典型的小样本场景。
　　对于这项成果，也有业内人士指出 “可能很难实现”。一名杜克大学的计算机科学博士生告诉 DeepTech：“用很少的样本去生成很多的类，是一件非常反直觉的事情。虽然他做到了这一点，但后续依然需要将各种特征组合成现实中的真实事物。”
　　该博士生分析称，如果把人类的眉、目、鼻、口、耳这五官特征提取出来，然后通过伊利亚的方式整合到一起，可能可以组成世界上所有存在、不存在的人脸，但在训练模型的时候，依旧需要让机器知道真正的人脸是怎样的。
　　也就是说，模型通过伊利亚的方法训练之后，还需要再增加一个新的步骤来实现闭环，这个新的学习步骤如何实现，以及实现的难易程度，才是关键所在。并且，五官的特征也是需要从大量的、有标签的数据中来的。但他也承认，“从这个角度看，这篇论文的确提出了一个非常新颖的思路。”
　　最后，伊利亚强调这个研究尚处在早期阶段，但他对此充满信心。
　　他说，每当他向其他研究人员介绍这篇论文时，他们的第一反应是说这个想法不可能实现，但紧接着他们便意识到事实并非如此，它可能无意间触及了一扇通往全新世界的大门。