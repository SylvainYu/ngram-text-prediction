原标题：专访加州大学伯克利分校教授Pieter Abbeel： 最终我们要给AI设置一个“关闭按钮” 否则很危险
　　打破机器人重复动作的局限，实现机器人自我学习、识别环境并反馈，人类应如何与AI相处？作为一种“新型电力”，AI及衍生机器人必定会在未来占据重要的一席之地，但想实现这一目标，实现广泛、普遍、合理使用AI的目标，人们仍需克服许多困难。
　　10月22日，第三方咨询机构安永发布报告指出，中国大陆企业对人工智能的未来发展持有相对谨慎和保守的态度，68%的受访企业预计，人工智能将在未来五年内，对行业产生较大甚至重大的影响；在政府的政策扶持和产业加快升级的背景下，企业的人工智能成熟度较高，但在网络安全、数据管理、创新管理等方面，尚存在不足。
　　2009到2019年间，中国大陆的人工智能投资笔数不断攀升，共累计投资2827亿人民币。在对人工智能的投资中，计算机视觉和智能机器人是主要投资领域。
　　一直以来，加州大学伯克利分校教授、伯克利人工智能实验室主任Pieter Abbeel主要的研究领域专注于机器人与机器学习，尤其在深度强化学习领域处于领先地位。同时，他还是 Covariant.Ai （仓库和工厂智能和机器人自动化）、Gradescope（人工智能打分系统）的联合创始人和首席科学家。
　　近日，他在接受21世纪经济报道记者专访时认为，从工业机器人到家用机器人的发展过程中，最大的改变是，将重复动作的机器人转变为机器人2.0，即能看见并能根据所处的情况产生反馈的机器人。今年以来，机器人对环境作出反馈的功能，已经发挥了实用功能。
　　值得人类关注的是，当AI真正“觉醒”后，它们会统治世界吗？AI与人类惧怕的恶距离有多远？
　　以下为对话实录：
　　《21世纪》：今年上半年，全球都受到了新冠肺炎疫情的影响。在人类生活中，AI扮演了怎样的角色？它会越来越重要吗？
　　Pieter Abbeel：在病毒大流行的背景下，像后勤基础设施这样迫使员工聚集的工作，变得危险且重要，因为我们每个人都需要在网上购物，就需要物流。因此，我希望大型仓库一类的场所运行起来可以更加自动化，更加安全可靠。另外，机器学习也有助于追踪事物的发展和控制。
　　我希望在未来，AI可以帮助人们应对病毒、进行医疗服务。目前，我们在疫苗研发和药物治疗方面没有明显的进展，但是我相信AI有潜力在医疗服务方面有突出贡献，远比我们目前所达到的成果更好。
　　《21世纪》：AI的发展分为几个阶段，您认为目前我们处于哪个阶段？
　　Pieter Abbeel：在最早的50-60年代，我们关注搜索和理论推理，发现AI可以证实一些人类尚无法证实的理论，也可以成为高超的棋手。但这些都基于非常清晰的规则，你可以理解为何AI会这样做。
　　在上世纪末和本世纪初，AI在模块识别和概率推理方面有了很大的进展。目前，受益于大量的数据，我们在这两方面有了更大的进步，比如说计算机视觉。尽管这一技术问题没有完全解决，但是在这过程中产生了许多成果，并投入到实际的商业活动中。
　　目前，我们正处于一个模块识别高度发达的阶段。人们想要解决一个问题，需要大量数据帮助计算机学习。
　　比如，机器人想要识别出一个行人或车辆，就需要在投入工作前学习无数行人和车辆的照片。但在未来，机器人可以自主学习，机器自动地去学习大量的数据，就像新生儿一样自主地观察世界，不需要人类去反复地教它，不需要标注大量信息。可能在未来五年，我们可以利用并看到无标识数据的影响，之后衍生出更多应用。
　　《21世纪》：普通人还不能在日常生活中应用深度强化学习，那么在目前这一阶段最大的困难和最急迫的需求是什么？
　　Pieter Abbeel：的确，深度强化学习离普通人的生活很远。但是，当我们考虑机器人只需要学习输入的图片，而非实际的动作或模仿时，科技已经有了很大的进步。在过去的几年里，我们将深度强化学习和自主学习相结合，发现向状态学习和向图像学习，可以达到同样的效果，我认为这是一个重要的突破。但是它还是不够高效，还需要进行大量测试。
　　另一方面，如果我想要落地一套系统，我不会从强制学习开始，而是从模仿开始。我会首先收集人们驾驶车辆、完成工作的示范，之后让机器人去模仿，这更加方便。之后再运用强制学习来提高、完善。
　　《21世纪》：我们距离广泛使用家用机器人还需要多长时间？在发展家用机器人的过程中，我们面临哪些困难和机遇？
　　Pieter Abbeel：每个家庭都有不同的情况、布置，有的家庭有宠物或者孩子，常常会把房间弄得一团糟。因此，当我考虑设计机器人时，就需要考虑机器人将来工作环境的构造。
　　我们可以在工厂里看到各种机器人在进行工作，但是它们只是在不停地重复同一个动作。
　　《21世纪》：AI已经被广泛应用在自动驾驶、医疗服务和教育等领域，将来还会在其他哪些领域展现商业潜力？
　　Pieter Abbeel：我的博士导师说，AI是新型电力，它将无处不在。我很同意他的观点。基于更多数据，很多人都可以对AI进行精准的预测，进而发挥其商业优势。
　　在2020年，我看到的最大变化有：一，语言处理。今年，出现了一些预测性语言模型，如Google开发的产品。这些模型相较于之前有了很大的进步，人们会基于此开发出许多应用。比如对话机器人、运动机器人、娱乐机器人，它们可以和人们流畅地对话，进而提高机器语言转化的能力。
　　二，机器人技术。许多事情不能仅仅靠重复动作来完成，你需要观察、反馈。未来几年，机器人将完成大部分人类的手部工作劳动。
　　在这一方面，尽管人们最常讨论的是自动驾驶技术，但我觉得它的开发进展要比人们想象中的更困难，因为AI可能产生的错误是致命的，而没有公司愿意让你知道他们的系统可能会致命，因此这一技术的可靠性还不够。在实验室，你可能会开发出一个十分优秀的自动驾驶产品，但当把它引入现实生活中时，不同的车辆会遇到不同的驾驶员，系统很难达到高度的可靠性。
　　《21世纪》：在诸如安全、隐私等领域，AI面临了哪些道德挑战？我们能有什么解决措施？
　　Pieter Abbeel：的确很多人都有这样的疑问，因为我们看到过很多AI未被合理使用的例子，比如侦测工具失灵、警察抓错嫌疑人等等。因此，我们应该对AI的道德问题保持谨慎的态度。如果一个人犯错了，那他只是犯了一个错误。但是如果AI犯错了，那么将会发生无数次错误。
　　问题的关键在于，如何在AI做出道德选择时测量它。尽管有时这一测量并不完美，但至少在测量后，我们可以开始研究并训练它做出更好的决定。在技术的发展下，会有好的解决方法，但的确还有很长的路要走。
　　《21世纪》：当AI真正“觉醒”后，您认为它们会统治世界吗？
　　Pieter Abbeel：我目前对这个问题还没有答案。在现实生活中，一个人更聪明并不意味着他就有更大的权力。但是，如果AI比人类聪明上十万倍，或许AI可能会统治世界或赚很多钱。这取决于我们想要的是什么，是要控制它们，还是当它们足够聪明后做任何自己想做的事情？这是一个复杂的问题。
　　《21世纪》：是否有什么措施可以防止事态发展到这一步？比如说设定一些程序的标准？
　　Pieter Abbeel：在伯克利有一个人类AI共存中心，我们也在研究怎样将AI置于控制之下，比如设置“关闭按钮”，但可能一个机器人会通过肢体或情感的方式，阻止你关闭它。所以我们需要一个能够理解人类正在观察它，但不能完全理解人类意图的AI系统。我们不希望AI能够完全知道人类的需求，否则就会很危险。
　　你不能给机器人十分明确、严格的目标，机器人需要知道它们并不理解一切。
　　（作者：陶力，张晟 编辑：李清宇）